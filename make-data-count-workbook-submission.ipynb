{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82370,"databundleVersionId":13015230,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bcookie11/lord-of-the-submits-return-of-the-overfit?scriptVersionId=260965798\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Data Collection (Meta / Text)\n\n- Dataclasses to extract articles from `.xml` and `.pdf` for model training / tunings.\n- Learning algorithm combines greedy search algorithm and cosine similarity distance scores to recommend tuple set ","metadata":{}},{"cell_type":"code","source":"import os\n\n# Silence TF/XLA/absl chatter that spams STDERR on Kaggle\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"        # 0=all,1=INFO,2=WARNING,3=ERROR\nos.environ[\"ABSL_LOGGING_MIN_LOG_LEVEL\"] = \"3\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nTRAIN_Y_PATH: str = \"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\"\nTRAIN_DIR_PATH:  str = \"/kaggle/input/make-data-count-finding-data-references/train\"\n\nMETA_PAPER_API = \"https://api.crossref.org/works/{doi}\"\nDEFAULT_SOURCE_TYPE = 'Unknown'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.516679Z","iopub.execute_input":"2025-09-10T03:00:08.5174Z","iopub.status.idle":"2025-09-10T03:00:08.521932Z","shell.execute_reply.started":"2025-09-10T03:00:08.517373Z","shell.execute_reply":"2025-09-10T03:00:08.521033Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Data Helpers and Utilities \n\nimport re\nimport io\nimport glob\nimport logging\nimport requests\nimport pandas as pd\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom pdfminer.high_level import extract_text\nfrom dataclasses import dataclass, field, asdict\nfrom typing import Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union, Any, Optional\n\nimport torch\nimport numpy as np\nimport urllib.parse as up\nfrom torch.utils.data import Dataset, DataLoader\nfrom sentence_transformers import SentenceTransformer\n\nlogger = logging.getLogger(\"kaggle_notebook\")\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter(\n    \"%(asctime)s | %(levelname)-8s | %(message)s\", \"%Y-%m-%d %H:%M:%S\"\n)\nhandler.setFormatter(formatter)\n\ndef _read_file_binary(path: str) -> bytes:\n    with open(path, \"rb\") as f:\n        return f.read()\n\ndef _clean_ws(text: str) -> str:\n    text = re.sub(r\"\\r\\n?\", \"\\n\", text)\n    text = re.sub(r\"[ \\t]+\", \" \", text)\n    text = re.sub(r\"\\n\\s*\\n\\s*\\n+\", \"\\n\\n\", text)  # collapse >2 blank lines\n    return text.strip()\n\ndef _pdf_to_text(path: str) -> str:\n    \"\"\"Extract text from PDF using pdfminer.six if available, else PyPDF2 as fallback.\"\"\"\n    # Try pdfminer.six (best quality)\n    try:\n        # Note: extract_text opens file internally; pass path.\n        text = extract_text(path) or \"\"\n        return _clean_ws(text)\n    except Exception:\n        pass\n\n    # Fallback: PyPDF2\n    try:\n        import PyPDF2  # type: ignore\n        text_chunks: List[str] = []\n        with open(path, \"rb\") as f:\n            reader = PyPDF2.PdfReader(f)\n            for pg in reader.pages:\n                try:\n                    s = pg.extract_text() or \"\"\n                except Exception:\n                    s = \"\"\n                if s:\n                    text_chunks.append(s)\n        return _clean_ws(\"\\n\\n\".join(text_chunks))\n    except Exception:\n        return \"\"\n\ndef _xml_to_text(path: str) -> str:\n    \"\"\"Parse XML with lxml if available, else ElementTree. Extracts title/abstract/body-ish text.\"\"\"\n    xml_bytes = _read_file_binary(path)\n\n    # Try lxml first (best for namespaces/xpaths).\n    try:\n        from lxml import etree  # type: ignore\n        parser = etree.XMLParser(recover=True, huge_tree=True)\n        root = etree.fromstring(xml_bytes, parser=parser)\n\n        # Common scholarly XML patterns (JATS-ish)\n        texts: List[str] = []\n\n        # title\n        titles = root.xpath(\"//article-title|//title-group//article-title|//title\")\n        titles = [t.text if isinstance(t, etree._Element) else str(t) for t in titles]\n        titles = [t for t in titles if t]\n        if titles:\n            texts.append(\"# \" + titles[0].strip())\n\n        # abstract\n        abs_nodes = root.xpath(\"//abstract//p|//Abstract//p|//abstract\")\n        for n in abs_nodes:\n            s = \"\".join(n.itertext()) if hasattr(n, \"itertext\") else str(n)\n            s = s.strip()\n            if s:\n                texts.append(s)\n\n        # body\n        body_nodes = root.xpath(\"//body//p|//sec//p|//Body//p\")\n        for n in body_nodes:\n            s = \"\".join(n.itertext()) if hasattr(n, \"itertext\") else str(n)\n            s = s.strip()\n            if s:\n                texts.append(s)\n\n        # fallback: all text\n        if not texts:\n            all_text = \" \".join(root.itertext())\n            texts = [all_text]\n\n        return _clean_ws(\"\\n\\n\".join(texts))\n\n    except Exception:\n        # Fallback to stdlib ElementTree\n        import xml.etree.ElementTree as ET\n\n        try:\n            root = ET.fromstring(xml_bytes)\n        except Exception:\n            return \"\"  # unreadable\n\n        def itxt(el):\n            try:\n                return \"\".join(el.itertext())\n            except Exception:\n                return el.text or \"\"\n\n        # Attempt similar sections by tag name\n        parts: List[str] = []\n        # naive title\n        for tag in (\"article-title\", \"title\"):\n            for n in root.iter(tag):\n                s = (n.text or \"\").strip()\n                if s:\n                    parts.append(\"# \" + s)\n\n        # abstract\n        for tag in (\"abstract\",):\n            for n in root.iter(tag):\n                s = itxt(n).strip()\n                if s:\n                    parts.append(s)\n\n        # paragraphs\n        for tag in (\"p\",):\n            for n in root.iter(tag):\n                s = itxt(n).strip()\n                if s:\n                    parts.append(s)\n\n        if not parts:\n            parts = [itxt(root)]\n\n        return _clean_ws(\"\\n\\n\".join([p for p in parts if p]))\n\n@dataclass\nclass Author:\n    family: Optional[str] = None\n    given: Optional[str] = None\n    literal: Optional[str] = None\n\n@dataclass\nclass Issued:\n    date_parts: List[List[int]] = field(default_factory=list)\n\n@dataclass\nclass DoiResponse:\n    type: str\n    id: str\n    categories: List[str]\n    author: List[Author]\n    issued: Issued\n    abstract: str\n    DOI: str\n    publisher: str\n    title: str\n    URL: str\n    copyright: str\n\n    @staticmethod \n    def parse_response(data: Dict[str, Any]):\n        authors = [Author(**a) for a in data.get(\"author\", [])]\n        issued = Issued(date_parts=data.get(\"issued\", {}).get(\"date-parts\", []))\n        return DoiResponse(\n            type=data.get(\"type\", \"\"),\n            id=data.get(\"id\", \"\"),\n            categories=data.get(\"categories\", []),\n            author=authors,\n            issued=issued,\n            abstract=data.get(\"abstract\", \"\"),\n            DOI=data.get(\"DOI\", \"\"),\n            publisher=data.get(\"publisher\", \"\"),\n            title=data.get(\"title\", \"\"),\n            URL=data.get(\"URL\", \"\"),\n            copyright=data.get(\"copyright\", \"\"),\n        )\n\n\n    @staticmethod\n    def parse_crossref(data: Dict[str, Any]):\n        \"\"\"Parse Crossref API `message` response into DoiResponse.\"\"\"\n        authors = [Author(**{k: v for k, v in a.items() if k in (\"given\",\"family\",\"literal\")}) \n                   for a in data.get(\"author\", [])]\n        issued = Issued(date_parts=data.get(\"issued\", {}).get(\"date-parts\", []))\n        return DoiResponse(\n            type=data.get(\"type\", \"\"),\n            id=data.get(\"DOI\", \"\"),  # Crossref uses DOI as ID\n            categories=data.get(\"subject\", []),\n            author=authors,\n            issued=issued,\n            abstract=data.get(\"abstract\", \"\"),\n            DOI=data.get(\"DOI\", \"\"),\n            publisher=data.get(\"publisher\", \"\"),\n            title=\"\".join(data.get(\"title\", [])) if isinstance(data.get(\"title\"), list) else data.get(\"title\", \"\"),\n            URL=data.get(\"URL\", \"\"),\n            copyright=data.get(\"license\", [{}])[0].get(\"URL\", \"\"),\n        )\n        \n@dataclass\nclass Article:\n    article_id: str \n    text: str \n    extension: str \n    source: str = DEFAULT_SOURCE_TYPE\n    dataset_id: str | None = None \n    dataset_id_cited: str | None = None\n    embedding: np.ndarray | None = None\n    file_path: str | Path | None = None \n    \n    @staticmethod\n    def fetch_meta_external(input_doi: str) -> dict | None:\n        url = META_PAPER_API.format(doi=input_doi)\n        \n        try:\n            r = requests.get(url)\n            return r.json()\n        except Exception as e: \n            logger.error(e)\n            return None\n\n    @staticmethod\n    def fetch_meta_doi(doi_url: str) -> DoiResponse | None:\n        try:\n            headers = {\"Accept\": \"application/vnd.citationstyles.csl+json\"}\n            r = requests.get(doi_url, headers=headers, timeout=30)\n            if r.status_code == 200:\n                result = r.json()\n                return DoiResponse.parse_response(result)\n                \n        except Exception as e: \n            logger.error(e)\n            return None\n            \n    @staticmethod\n    def fetch_meta_crossref(doi: str) -> DoiResponse | None:\n        \"\"\"\n        Fetch metadata for a DOI from the Crossref API and return a DoiResponse object.\n        \"\"\"\n        try:\n            api_url = f\"https://api.crossref.org/works/{up.quote(doi)}\"\n            r = requests.get(api_url, headers={\"User-Agent\":\"Mozilla/5.0\"}, timeout=15)\n            r.raise_for_status()\n            data = r.json().get(\"message\", {})\n            return DoiResponse.parse_crossref(data)\n        except Exception as e:\n            logger.error(\"Crossref fetch failed for %s: %s\", doi, e)\n            return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.52501Z","iopub.execute_input":"2025-09-10T03:00:08.525223Z","iopub.status.idle":"2025-09-10T03:00:08.55678Z","shell.execute_reply.started":"2025-09-10T03:00:08.525208Z","shell.execute_reply":"2025-09-10T03:00:08.556015Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Dataset ID / URL Cleaners & Converters \nimport re \n# Test datasets that could possibly exist in the data\nsamples = [\n    {\n        \"dataset_id\": \"https://doi.org/10.1098/rspb.2016.1151\",\n        \"data\": [\"https://doi.org/10.5061/dryad.6m3n9\"],\n        \"in_text_span\": \"The data we used in this publication can be accessed from Dryad at doi:10.5061/dryad.6m3n9.\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.1098/rspb.2018.1563\",\n        \"data\": [\"https://doi.org/10.5061/dryad.c394c12\"],\n        \"in_text_span\": \"Phenotypic data and gene sequences are available from the Dryad Digital Repository: http://dx.doi.org/10.5061/dryad.c394c12\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.1534/genetics.119.302868\",\n        \"data\": [\"https://doi.org/10.25386/genetics.11365982\"],\n        \"in_text_span\": \"The authors state that all data necessary for confirming the conclusions presented in the article are represented fully within the article. Supplemental material available at figshare: https://doi.org/10.25386/genetics.11365982.\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.1038/sdata.2014.33\",\n        \"data\": [\"GSE37569\", \"GSE45042\", \"GSE28166\"],\n        \"in_text_span\": \"Primary data for Agilent and Affymetrix microarray experiments are available at the NCBI Gene Expression Omnibus (GEO, http://www.ncbi.nlm.nih.gov/geo/) under the accession numbers GSE37569, GSE45042 , GSE28166\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.12688/wellcomeopenres.15142.1\",\n        \"data\": [\"pdb 5yfp\"],\n        \"in_text_span\": \"Figure 1. Evolution and structure of the exocyst... All structural images were modelled by the authors from PDB using UCSF Chimera.\",\n        \"citation_type\": \"Secondary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.3389/fimmu.2021.690817\",\n        \"data\": [\"E-MTAB-10217\", \"PRJE43395\"],\n        \"in_text_span\": \"The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found below: https://www.ebi.ac.uk/arrayexpress/, E-MTAB-10217 and https://www.ebi.ac.uk/ena, PRJE43395.\",\n        \"citation_type\": \"Secondary\",\n    },\n]\n\nACCESSION_PATTERNS = [\n    # DOI (bare \"10.\" prefix, or full http(s) doi.org link, or \"doi:10...\")\n    (re.compile(r\"^(?:https?://(?:dx\\.)?doi\\.org/|doi:)?(10\\.\\d{4,9}/\\S+)$\", re.I),\n     lambda m: f\"https://doi.org/{m.group(1)}\"),\n\n    # GEO (Gene Expression Omnibus)\n    (re.compile(r\"^GSE\\d+$\", re.I),\n     lambda m: f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={m.group(0)}\"),\n\n    # ENA run/experiment (ERR/ERS/SRR/DRR/etc.)\n    (re.compile(r\"^(ERR|ERS|SRR|SRX|SRP|DRR|DRX|DRP|ERX|ERP)\\d+$\", re.I),\n     lambda m: f\"https://www.ebi.ac.uk/ena/browser/view/{m.group(0)}\"),\n\n    # dbSNP rs IDs\n    (re.compile(r\"^rs\\d+$\", re.I),\n     lambda m: f\"https://www.ncbi.nlm.nih.gov/snp/{m.group(0)}\"),\n\n    # PDB (4-char alphanumeric IDs)\n    (re.compile(r\"^[0-9A-Za-z]{4}$\"),\n     lambda m: f\"https://www.rcsb.org/structure/{m.group(0)}\"),\n\n    # ChEMBL compounds/targets/assays\n    (re.compile(r\"^CHEMBL\\d+$\", re.I),\n     lambda m: f\"https://www.ebi.ac.uk/chembl/compound_report_card/{m.group(0)}/\"),\n\n    # DDBJ/GenBank/RefSeq nucleotide accessions (D10700, CP013147, NC_#######)\n    (re.compile(r\"^(?:[A-Z]{1,2}\\d{5,6}|NC_\\d+)$\", re.I),\n     lambda m: f\"https://www.ncbi.nlm.nih.gov/nuccore/{m.group(0)}\"),\n]\n\ndef resolve_accession(acc: str) -> Optional[str]:\n    \"\"\"Return a URL for any accession/identifier/DOI.\"\"\"\n    \n    if acc is None or (isinstance(acc, float) and pd.isna(acc)):\n        return None\n        \n    s = str(acc).strip()\n    if not s:\n        return None\n\n    # Try regex patterns\n    for pattern, builder in ACCESSION_PATTERNS:\n        m = pattern.match(s)\n        if m:\n            return builder(m)\n\n    # Special-case string prefixes\n    if s.upper().startswith(\"ENS\"):  # Ensembl\n        return f\"https://www.ensembl.org/id/{s}\"\n    if s.upper().startswith(\"IPR\"):  # InterPro\n        return f\"https://www.ebi.ac.uk/interpro/entry/{s.upper()}\"\n    if s.upper().startswith(\"CVCL_\"):  # Cellosaurus\n        return f\"https://www.cellosaurus.org/{s.upper()}\"\n    if s.upper().startswith(\"EMPIAR-\"):  # EMPIAR\n        return f\"https://www.ebi.ac.uk/empiar/{s.upper()}\"\n    if s.upper().startswith(\"HGNC:\"):  # HGNC gene IDs\n        return f\"https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/{s.upper()}\"\n    if re.match(r\"^K\\d{5}$\", s, flags=re.I):  # KEGG Orthology\n        return f\"https://www.genome.jp/dbget-bin/www_bget?ko:{s.upper()}\"\n    if s.upper().startswith(\"EPI_ISL_\"):  # GISAID\n        return f\"https://www.gisaid.org/search?query={s}\"\n\n    # If it's already an HTTP(S) URL but didn't match DOI/PDB etc., keep as-is\n    if s.lower().startswith(\"http\"):\n        return s\n\n    # Fallback\n    return s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.709731Z","iopub.execute_input":"2025-09-10T03:00:08.709929Z","iopub.status.idle":"2025-09-10T03:00:08.720997Z","shell.execute_reply.started":"2025-09-10T03:00:08.709915Z","shell.execute_reply":"2025-09-10T03:00:08.720354Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import numpy as np \nfrom tqdm import tqdm, trange\nfrom sentence_transformers import SentenceTransformer\n\ntqdm.pandas()\n\nMODEL_NAME = \"all-MiniLM-L6-v2\"\nK = 5\n# Data fields IDs\n# dropped all in the list\nID_LABELS = [\"dataset_id\", \"article_id\", \"id\", \"DOI\", \"url\"]\n# data columns included in the input batch\n# dropped: issued, embedding, author, text\nTRAIN_LABELS = [ 'title', 'segments', 'extension', 'abstract', 'publisher', 'copyright', 'issued_year', 'all_authors', 'categories']\nALL_FIELDS = [\n    'article_id','text','extension','source','dataset_id','dataset_id_cited','type',\n    'id','categories','abstract','DOI','publisher','title','URL','copyright',\n    'issued_year','all_authors','y'\n]\n\ndef prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n    \n    df = df.copy()\n    # Extracts the issued year from the issued date\n    df[\"issued_year\"] = (\n        pd.json_normalize(df[\"issued\"])\n        .explode(\"date_parts\")[\"date_parts\"]\n        .map(lambda x: int(x[0]) if isinstance(x, np.ndarray) and len(x) > 0 else None)\n    )\n    # EXTRACT AUTHORS\n\n    author_snippets = [\n        [\n            \" \".join(k for k in (j.get(\"family\"), j.get(\"given\"), j.get(\"literal\")) if k)\n            for j in i\n        ]\n        if isinstance(i, (list, np.ndarray))\n        else tuple()\n        for i in df[\"author\"].values\n    ]\n\n    assert len(author_snippets) == df.shape[0], (\n        f\"Expected {df.shape[0]} number of authors (tuples) in dataset but parsed {len(author_snippets)}. Fix query.\"\n    )\n\n    df['all_authors'] = author_snippets\n    output_fields = [i for i in ALL_FIELDS if i in df.columns]\n    \n    # CREATE TARGET LABELS\n    if 'source' in df.columns:\n        df[\"y\"] = df[\"source\"].map({\"Primary\": 0, \"Secondary\": 1, \"Missing\": 2, \"Unknown\": 3})\n        return df[~df['source'].isin(['Missing', 'Unknown'])][output_fields]\n        \n    return df[output_fields]\n    \ndef load_train_dataset():\n    \"\"\" Loads the dataset for training. The train data has labels from `../train_labels.csv`. Label fields are: (`article_id`, `dataset_id`, `type`) i.e. the predicting variables. \"\"\"\n    \n    targets = pd.read_csv(TRAIN_Y_PATH)\n    logger.info(f\"Total distinct ref type Labels: {targets['type'].unique()}\")\n    \n    for path in tqdm(Path(\"/kaggle/input\").rglob(\"*\"), desc=\"Loaded Train dataset.\"):\n        if path.parents[1].stem == 'train' and path.is_file():\n            info = {}\n            \n            ext = path.suffix\n            \n            if ext == '.pdf': \n                text = _pdf_to_text(str(path))\n            elif ext == '.xml': \n                text = _xml_to_text(str(path))\n\n            meta = targets[targets['article_id'] == path.stem]\n            \n            info['extension'] = ext \n            info['text'] = text \n            info['article_id'] = path.stem\n            info['file_path'] = str(path)\n            # info['embedding'] = model.encoder(info['text']) if text != '' else None\n            \n            if not meta.empty:\n                # only gets the first data entry meta . . .\n                metas = meta.iloc[0].to_dict()\n                info[\"source\"] = metas.get(\"type\", DEFAULT_SOURCE_TYPE)\n                info[\"dataset_id\"] = metas.get(\"dataset_id\", None)\n                info[\"dataset_id_cited\"] = resolve_accession(info[\"dataset_id\"]) if info[\"dataset_id\"] is not None else None\n            else:\n                logger.warning(\"No metadata found for %s\", path.stem)\n\n            yield Article(**info)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.722164Z","iopub.execute_input":"2025-09-10T03:00:08.722392Z","iopub.status.idle":"2025-09-10T03:00:08.738664Z","shell.execute_reply.started":"2025-09-10T03:00:08.722369Z","shell.execute_reply":"2025-09-10T03:00:08.737801Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Main Caller \n\nclass DoiData(Dataset): \n    \"\"\" Doi Dataset handler. \n    Target types:\n    'Unknown': missing from train dataset\n    'Missing': missing from data - predefined in the dataset\n    'Primary' / 'Secondary': Main Data Referencing Labels\n    \"\"\"\n    \n    def __init__(self):\n        self.data = list(load_train_dataset())\n\n        assert len(self.data) > 0, \"Empty dataset loaded to instance. Pls reconfigure path or data parser.\"\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx: int): \n        if idx > len(self.data) or idx < 0:\n            raise ValueError('Index out of range. Pls reconfigure processor.')\n\n        # TODO: CONVERT TO X_train, y_train outputs\n        article = self.data[idx]\n        \n        if article.dataset_id_cited:\n            if meta := Article.fetch_meta_doi(article.dataset_id_cited):\n                return {**asdict(article), **asdict(meta)}\n                \n        return asdict(article)\n\ndef setup_test_dataset() -> pd.DataFrame:\n    parquet_path = Path(\"/kaggle/working/test_dataset.parquet\")\n\n    # If parquet already exists, load and return it\n    if parquet_path.exists():\n        return pd.read_parquet(parquet_path)\n\n    # Otherwise build from scratch\n    test_data = []\n    \n    for path in tqdm(Path(\"/kaggle/input\").rglob(\"*\"), desc=\"Loaded Test dataset\"):\n        if path.is_file() and path.parents[1].stem == \"test\":\n            info = {}\n            \n            file_path = str(path)\n            ext = path.suffix\n            stem = path.stem\n            doi = stem.replace(\"_\", \"/\", 1)\n            \n            print(f\"Retrieved test: {doi}\")\n            \n            if ext == \".xml\":\n                text = _xml_to_text(file_path)\n            elif ext == \".pdf\":\n                text = _pdf_to_text(file_path)\n            else:\n                continue  # skip unsupported files\n            \n            info[\"extension\"] = ext\n            info[\"text\"] = text\n            info[\"article_id\"] = path.stem\n            info[\"file_path\"] = file_path\n            info[\"dataset_id\"] = resolve_accession(doi)\n            info[\"dataset_id_cited\"] = resolve_accession(doi)\n            \n            if meta := Article.fetch_meta_crossref(info[\"dataset_id_cited\"]):\n                info.update(**asdict(meta))\n            \n            test_data.append(info)\n    \n    test_data = pd.DataFrame.from_records(test_data)\n    test_dataset = prepare_data(test_data)\n\n    # Save for reuse\n    test_dataset.to_parquet(parquet_path)\n    # test_dataset.to_csv(parquet_path.with_suffix(\".csv\"), index=False)\n\n    return test_dataset\n    \ndef setup_train_dataset() -> pd.DataFrame:\n    parquet_path = Path(\"/kaggle/working/train_dataset.parquet\")\n\n    # If parquet already exists, load and return it\n    if parquet_path.exists():\n        return pd.read_parquet(parquet_path)\n\n    # Otherwise build from scratch\n    ds = DoiData()\n    full_data = list(ds)\n    data = pd.DataFrame.from_records(full_data)\n    train_dataset = prepare_data(data)\n\n    # Save for reuse\n    train_dataset.to_parquet(parquet_path)\n    # train_dataset.to_csv(parquet_path.with_suffix(\".csv\"), index=False)\n\n    return train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.739421Z","iopub.execute_input":"2025-09-10T03:00:08.739638Z","iopub.status.idle":"2025-09-10T03:00:08.750359Z","shell.execute_reply.started":"2025-09-10T03:00:08.739619Z","shell.execute_reply":"2025-09-10T03:00:08.74962Z"},"scrolled":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Prepare Train & Test Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers.util import cos_sim\n\ntqdm.pandas()\n\nMODEL_NAME = \"all-MiniLM-L6-v2\"\nK = 5\nID_LABELS = [\"dataset_id\", \"article_id\", \"id\", \"DOI\", \"url\"]\nTRAIN_LABELS = [\n    'title', 'segments', 'extension', 'abstract', 'publisher',\n    'copyright', 'issued_year', 'all_authors', 'categories'\n]\nALL_FIELDS = [\n    'article_id','text','extension','source','dataset_id','dataset_id_cited','type',\n    'id','categories','abstract','DOI','publisher','title','URL','copyright',\n    'issued_year','all_authors','y'\n]\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nclass Basement(SentenceTransformer):\n    def __init__(self, initial_data: pd.DataFrame):\n        super().__init__(MODEL_NAME, device=DEVICE)\n        self.x = self.preprocess_data(initial_data)\n        self.to(DEVICE)\n        self.eval()\n        for p in self.parameters():\n            p.requires_grad = False\n\n    def _meta_conditioner(self, row):\n        combined_prompt = f\"\"\"\n        Title: {row.get('title', '')}\n        Abstract: {row.get('abstract', '')}\n        Author: {row.get('all_authors', '')}\n        Extension File Type: {row.get('extension', '')}\n        Publisher: {row.get('publisher', '')}\n        Category: {row.get('categories', '')}\n        Issued Year: {row.get('issued_year', '')}\n        Copyright: {row.get('copyright', '')}\n        \"\"\"\n        meta_embedding = self.encode(\n            [combined_prompt],\n            convert_to_numpy=True,\n            output_value=\"sentence_embedding\",\n            show_progress_bar=False\n        )\n        text_embedding = row.get('segments', None)\n\n        if isinstance(text_embedding, np.ndarray):\n            if text_embedding.ndim == 1:\n                text_embedding = np.expand_dims(text_embedding, axis=0)\n            return np.vstack((meta_embedding, text_embedding))\n\n        return meta_embedding  # fallback to meta only\n\n    def _segment_text(self, s: str, k: int = K) -> np.ndarray:\n        if not isinstance(s, str) or not s:\n            return np.zeros((k, self.get_sentence_embedding_dimension()), dtype=np.float32)\n        n = len(s)\n        idx = np.linspace(0, n, k + 1, dtype=int)\n        chunks = [s[idx[i]:idx[i+1]] for i in range(k)]\n        emb = self.encode(chunks, convert_to_numpy=True, show_progress_bar=False)\n        return np.asarray(emb, dtype=np.float32).reshape(k, -1)\n\n    def preprocess_data(\n        self,\n        data: pd.DataFrame,\n        k: int = K,\n        train_labels: list[str] | None = None\n    ) -> pd.DataFrame:\n        train_labels = train_labels or TRAIN_LABELS\n        df = data.copy()\n\n        # 1) create 'segments'\n        df[\"segments\"] = df[\"text\"].apply(lambda x: self._segment_text(x, k))\n\n        # 2) explode multi-valued columns\n        for col in (\"all_authors\", \"segments\", \"categories\"):\n            if col in df.columns:\n                df = df.explode(col, ignore_index=True)\n\n        # 3) drop duplicated rows\n        subset_cols = [c for c in train_labels if c in df.columns and c != \"segments\"]\n        if subset_cols:\n            df = df.drop_duplicates(subset=subset_cols, keep=\"first\")\n\n        # 4) fills / cleaning\n        if \"issued_year\" in df.columns:\n            mode_series = df[\"issued_year\"].dropna().mode()\n            if not mode_series.empty:\n                df[\"issued_year\"] = df[\"issued_year\"].fillna(mode_series.iloc[0])\n\n        if \"copyright\" in df.columns:\n            df[\"copyright\"] = (\n                df[\"copyright\"].astype(\"string\").str.strip().replace({\"\": \"Unknown\"})\n            )\n\n        if \"categories\" in df.columns:\n            df[\"categories\"] = df[\"categories\"].astype(\"string\").fillna(\"Unknown\")\n\n        df[\"inputs\"] = df.apply(self._meta_conditioner, axis=1)\n        \n        return df\n\n    def predict_from_temporal_state(self, inputs: dict): \n        # uses greedy algorithm to get highest average similarities across fields: `dataset_id`, `article_id`, `type/ source` \n        pass \n        \n    def predict(self, inputs: dict, threshold: float = 0.5):\n        # disadvantage of this method is that it is strictly greater than previous scores .. can be shit \n        \n        text = inputs.get(\"text\")\n        \n        if not text:\n            print('Skipping this dataset as it is probably hidden test set.')\n            # measure against seen \n            return None\n            \n        # Query embedding\n        segment = self._segment_text(text)\n        inputs = dict(inputs, segments=segment)\n        input_emb = self._meta_conditioner(inputs)\n        \n        if input_emb.ndim == 1:\n            input_emb = input_emb.reshape(1, -1)\n            \n        q = input_emb.mean(axis=0, keepdims=True)\n\n        q_tensor = torch.tensor(q, device=DEVICE, dtype=torch.float32)\n\n        max_pred = None\n        for grp, row in self.x.groupby(['article_id', 'dataset_id', 'source']):\n            valid_inputs = [\n                x for x in row['inputs'].values\n                if isinstance(x, np.ndarray) and x.size > 0\n            ]\n            if not valid_inputs:\n                continue\n\n            train_sample = np.vstack(valid_inputs)\n            train_tensor = torch.tensor(train_sample, device=DEVICE, dtype=torch.float32)\n\n            avg = float(cos_sim(train_tensor, q_tensor).mean())\n            prev = max_pred['score'] if max_pred else None\n            if (max_pred is None) or (avg > prev):\n                source_type = grp[2] if avg >= threshold else (\n                    \"Primary\" if grp[2] == \"Secondary\" else \"Secondary\" if grp[2] == \"Primary\" else grp[2]\n                )\n                \n                max_pred = {\n                    'article_id': grp[0],\n                    'dataset_id': grp[1],\n                    'type': source_type,\n                    'score': avg,\n                }\n        return max_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.752054Z","iopub.execute_input":"2025-09-10T03:00:08.752725Z","iopub.status.idle":"2025-09-10T03:00:08.770581Z","shell.execute_reply.started":"2025-09-10T03:00:08.752698Z","shell.execute_reply":"2025-09-10T03:00:08.769825Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#test_dataset.to_parquet('/kaggle/working/test_dataset.parquet')\n#train_dataset.to_parquet('/kaggle/working/train_dataset.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.771357Z","iopub.execute_input":"2025-09-10T03:00:08.771555Z","iopub.status.idle":"2025-09-10T03:00:08.78218Z","shell.execute_reply.started":"2025-09-10T03:00:08.771541Z","shell.execute_reply":"2025-09-10T03:00:08.781265Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_data = setup_train_dataset()\ntest_data = setup_test_dataset()\n\nbase = Basement(train_data)\nprediction = []\n\nfor _, row in test_data.iterrows():\n    pred = base.predict(row.to_dict())\n    if pred:\n        prediction.append(pred)\n\nsubmission = pd.DataFrame.from_records(prediction)\nsubmission = submission.sort_values([\"article_id\", \"dataset_id\", \"type\"]).reset_index(drop=True)\nsubmission['row_id'] = submission.index\n\nsubmission[['row_id', 'article_id', 'dataset_id', 'type']].to_csv('/kaggle/working/submission.csv', index=False)\nprint(f'data submitted! Saving {submission.shape[0]} submissions :3', submission.head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T03:00:08.782937Z","iopub.execute_input":"2025-09-10T03:00:08.783203Z","iopub.status.idle":"2025-09-10T03:01:43.981055Z","shell.execute_reply.started":"2025-09-10T03:00:08.783176Z","shell.execute_reply":"2025-09-10T03:01:43.980205Z"}},"outputs":[{"name":"stdout","text":"data submitted! Saving 55 submissions :3              article_id                             dataset_id     type  \\\n0  10.1002_2017jc013030         https://doi.org/10.17882/49388  Primary   \n1  10.1002_2017jc013030         https://doi.org/10.17882/49388  Primary   \n2     10.1002_ece3.4466  https://doi.org/10.5061/dryad.r6nq870  Primary   \n3     10.1002_ece3.4466  https://doi.org/10.5061/dryad.r6nq870  Primary   \n4     10.1002_ece3.5260  https://doi.org/10.5061/dryad.2f62927  Primary   \n\n      score  row_id  \n0  0.799067       0  \n1  0.800693       1  \n2  0.937313       2  \n3  0.943509       3  \n4  0.883945       4  \n","output_type":"stream"}],"execution_count":29}]}